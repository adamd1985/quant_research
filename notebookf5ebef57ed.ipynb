{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":98.905855,"end_time":"2023-11-05T18:01:13.607303","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-05T17:59:34.701448","version":"2.4.0"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":149408112,"sourceType":"kernelVersion"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Solving for the Efficient Frontier in Stock Portfolios","metadata":{"papermill":{"duration":0.00682,"end_time":"2023-11-05T17:59:38.297125","exception":false,"start_time":"2023-11-05T17:59:38.290305","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/addarm/efficient-frontier-quant\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{"papermill":{"duration":0.005778,"end_time":"2023-11-05T17:59:38.309438","exception":false,"start_time":"2023-11-05T17:59:38.303660","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<!-- @import \"[TOC]\" {cmd=\"toc\" depthFrom=1 depthTo=6 orderedList=false} -->\n\n![Riding the efficient frontier Mind Valley 11.2023](https://raw.githubusercontent.com/adamd1985/quant_research/main/images/frontier_banner.png)\n\nThe Efficient Frontier, a core concept in Harry Markowitz's Modern Portfolio Theory (MPT), is used in quantitative finance to build optimal portfolios that offer the highest expected return for a given level of risk and/or the lowest risk for a given level of return. \n\nIt is constructed by diversifying assets to find the best risk-return trade-off, which we will do in this article, through python and free financial data. The resulting universe of assets and portfolios should lie on the **efficient frontier**.\n\n## Prepare your Environment\n\nHave a jupyter environment ready, and `pip install` these libraries:\n- numpy\n- pandas\n- yfinance\n\nYou'll need access to [analysis_utils](./analysis_utils.py) library for common functions.","metadata":{"papermill":{"duration":0.005624,"end_time":"2023-11-05T17:59:38.321019","exception":false,"start_time":"2023-11-05T17:59:38.315395","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\n\nimport dotenv\n%load_ext dotenv\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nIS_KAGGLE = os.getenv('IS_KAGGLE', 'True') == 'True'\n\nif IS_KAGGLE:\n    # Kaggle confgs\n    print('Running in Kaggle...')\n    %pip install yfinance\n    %pip install statsmodels\n    %pip install seaborn\n    %pip install itertools\n    %pip install scikit-learn\n\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\nelse:\n    print('Running Local...')\n\nimport yfinance as yf\nfrom analysis_utils import calculate_profit, load_ticker_prices_ts_df, plot_strategy, load_ticker_ts_df","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":84.119909,"end_time":"2023-11-05T18:01:02.447010","exception":false,"start_time":"2023-11-05T17:59:38.327101","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T19:06:15.672300Z","iopub.execute_input":"2023-11-19T19:06:15.672714Z","iopub.status.idle":"2023-11-19T19:07:42.874358Z","shell.execute_reply.started":"2023-11-19T19:06:15.672676Z","shell.execute_reply":"2023-11-19T19:07:42.871901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before we start, let's load two uncorrelated securities from the latest post-covid market regime (2020-2023) to build a test portfolio:","metadata":{}},{"cell_type":"code","source":"tickers = [\"DIS\", \"AAPL\"]\n\nSTART_DATE = \"2021-01-01\"\nEND_DATE = \"2022-12-31\"\n\ntickers_orig_df = load_ticker_prices_ts_df(tickers, START_DATE, END_DATE)\ntickers_df = tickers_orig_df.dropna(axis=1).pct_change().dropna()  # first % is NaN\n\n# 1+ to allow the cumulative product of returns over time, and -1 to remove it at the end.\ntickers_df = (1 + tickers_df).cumprod() - 1\n\nplt.figure(figsize=(16, 8))\nfor ticker in tickers_df.columns:\n    plt.plot(tickers_df.index, tickers_df[ticker] * 100.0, label=ticker)\n\nplt.xlabel(\"Date (Year-Month)\")\nplt.ylabel(\"Cummulative Returns(%\")\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":0.801372,"end_time":"2023-11-05T18:01:03.258937","exception":false,"start_time":"2023-11-05T18:01:02.457565","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-19T19:07:42.875967Z","iopub.status.idle":"2023-11-19T19:07:42.876459Z","shell.execute_reply.started":"2023-11-19T19:07:42.876243Z","shell.execute_reply":"2023-11-19T19:07:42.876265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For each stock above `(i)`, we are interested in:\n- The mean historic returns, which we will use as expected returns `E(Ri)` (a naive, but common assumption in MPT).\n- The variance `var(i)` or `sigma(i)^2`, and the normalized standard deviaion `sigma(i)`.\n- Price weights `Xi`, which we will allocate or calculate throughout this article.","metadata":{}},{"cell_type":"code","source":"mean_returns = tickers_df.mean()\nhighest_returns = tickers_df.max()\nlowest_returns = tickers_df.min()\nstd_deviation = tickers_df.std()\nsummary_table = pd.DataFrame(\n    {\n        \"Highest ret (%)\": highest_returns * 100.0,\n        \"Average ret (%)\": mean_returns * 100.0,\n        \"Lowest ret (%)\": lowest_returns * 100.0,\n        \"Deviation (%)\": std_deviation * 100.0,\n    }\n)\nsummary_table.transpose()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:07:42.877966Z","iopub.status.idle":"2023-11-19T19:07:42.878415Z","shell.execute_reply.started":"2023-11-19T19:07:42.878212Z","shell.execute_reply":"2023-11-19T19:07:42.878233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Investment Preferences with Indifference Curves\n\nTo understand the efficient fontier we need to experiment with the investors choices of risk/reward, through indifference curves.\nThe curves model satisfaction or utility from investment decisions, and help to visualize the optimal positions to take.\nWe use opportunity sets to outline viable combinations of assets' risk and returns, within linear budget constraints. \n\nAssume the following opportunities:\n1. We have a 5% risk free return (at the time of writing 11.2023)\n2. We have a choice of taking no risk for 5%, or for this example: taking 40% risk for 145% gains wih AAPL.\n\nLet's assume this is a risk averse investor, we model them by this utility function:\n$$ U(x) = x + ax^2 + bx + c $$\n- `x` is the risk from 1 to 100%\n- `a^2` & `bx` are the quadratic (concave as we penalize risk) and linear terms (sensitivity to variance with positive slope, we want more returns with more risk). Their coefficients `a` & `b` will be set to `0.15` & `0.1`.\n- `c` is a constant of increasing utility or satisfaction, incrementing it by 10 to create 3 curves.\nThe goal of the investor is to go up and to the left curves, to increase their utility. This means nothing under the `low utility` intersection, and nothing higher than `moderate utility` curve because there is no opportunity.\n\nThe optimal choice is when the opportunity set line is tangent to a curve, in our case the `moderate`, giving us 70% returns for 10% risk. ","metadata":{}},{"cell_type":"code","source":"def utility_fn(x, a=0.15, b=0.1, c=1):\n    return a * x**2 + b * x + c\n\n\nplt.figure(figsize=(16, 8))\n\nx_values_1 = np.linspace(0, 40, 100)\ny_values_1 = utility_fn(x_values_1, c=10)\nplt.plot(x_values_1, y_values_1, label=\"Low Utility\", alpha=0.6)\n\nx_values_2 = np.linspace(0, 35, 100)\ny_values_2 = utility_fn(x_values_2, c=24)\nplt.plot(x_values_2, y_values_2, label=\"Moderate Utility\", color=\"g\", alpha=0.6)\n\nx_values_3 = np.linspace(0, 30, 100)\ny_values_3 = utility_fn(x_values_3, c=35)\nplt.plot(x_values_3, y_values_3, label=\"High Utility\", color=\"r\", alpha=0.6)\n\nplt.plot([0, 40], [5, 140], label=\"Opportunity Set\", color=\"b\", linewidth=2)\n\nplt.plot([2, 2], [0, 12], linestyle=\"--\", color=\"b\", alpha=0.6, linewidth=2)\nplt.plot([0, 2], [12, 12], linestyle=\"--\", color=\"b\", alpha=0.6, linewidth=2)\nplt.plot([10, 10], [0, 40], linestyle=\"--\", color=\"g\", alpha=0.6, linewidth=2)\nplt.plot([0, 10], [40, 40], linestyle=\"--\", color=\"g\", alpha=0.6, linewidth=2)\nplt.plot([20, 20], [0, 72], linestyle=\"--\", color=\"b\", alpha=0.6, linewidth=2)\nplt.plot([0, 20], [72, 72], linestyle=\"--\", color=\"b\", alpha=0.6, linewidth=2)\n\nplt.xlabel(\"Risk %\")\nplt.ylabel(\"Returns %\")\nplt.title(\"Utility Curves (Risk Free VS AAPL)\")\nplt.legend()\nplt.grid()\n\nplt.xlim(0, 25)\nplt.ylim(0, 100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:07:42.880666Z","iopub.status.idle":"2023-11-19T19:07:42.881235Z","shell.execute_reply.started":"2023-11-19T19:07:42.880942Z","shell.execute_reply":"2023-11-19T19:07:42.880967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mean-Variance Portfolios\n\nTo build portfolios, we need to wieght our stocks according to their risk or dispertion. We will weight these and get the expected returns for our portfolios:\n\n$$ E(R_p) = \\sum_{i=1}^{N} w_{i} \\cdot E(R) $$\nWhere:\n- `E(Rp)` is the expected portfolio return, `E(R)` and `Rbar` are the same in this context.\n- `E(i)` is the expected return of the asset `i`.\n- `Wi` is the weight of the asset `i` in the portfolio. In this case we have only two assets.\n\nFirst we convert DIS and AAP to annualized returns and covariances:\n$$ \\text{Annualized Return} = \\left( \\prod_{i=1}^{n} (1 + R_i) \\right)^{\\frac{N}{n}} - 1 $$\n- `n` represents the number of data points or periods in your time series.\n- `Ri` represents the returns for each period. we `+1` to get the absolute returns.\n- `N` is the total number of trading days in a year (usually 252 for daily returns).\n\nWe annualized to scale up to represent a full year of risk/return, e.g.:\n- Daily return: `0.005` (0.5% return)\n- Annualized return: `0.005 * 252 = 1.26` (126% annualized return)","metadata":{}},{"cell_type":"code","source":"TRADING_DAYS_IN_YEAR = 252\n\ntickers_df = tickers_orig_df.dropna(axis=1).pct_change().dropna()\n\nrets = ((1 + tickers_df).prod() ** (TRADING_DAYS_IN_YEAR / len(tickers_df))) - 1\ncov_matrix = tickers_df.cov() * TRADING_DAYS_IN_YEAR\n\nsummary_table = pd.DataFrame(\n    {\n        \"Annualized Returns (%)\": round(rets * 100.0, 2),\n        \"Annualized Covariances (%)\": [\n            round(cov_matrix.iloc[1, 0] * 100.0, 2),\n            round(cov_matrix.iloc[0, 1] * 100.0, 2),\n        ],\n    }\n)\nsummary_table.transpose()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:07:42.882555Z","iopub.status.idle":"2023-11-19T19:07:42.883120Z","shell.execute_reply.started":"2023-11-19T19:07:42.882826Z","shell.execute_reply":"2023-11-19T19:07:42.882852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A portfolio is a weighted collection of assets. Assuming we don't weigh by the price ratios of the assets, we can already create some portfolios with arbitary wieghts - which we will test randomly below:","metadata":{}},{"cell_type":"code","source":"RISK_FREE_RATE = 0.05\nMAX_PORTS = 10000\nMAX_WEIGHT = 1.05\n\n\ndef port_generator(rets, cov_matrix):\n    port_rets = []\n    port_risks = []\n    port_sharpes = []\n    port_weights = []\n\n    for _ in range(MAX_PORTS):\n        # weights = np.random.random(len(rets))\n        weights = np.random.uniform(-MAX_WEIGHT, MAX_WEIGHT, len(rets))\n        weights /= np.sum(weights)  # Normalize weights to 1\n        if any(weights > MAX_WEIGHT):\n            continue\n        port_weights.append(weights)\n\n        port_ret = np.dot(weights, rets)\n        port_rets.append(port_ret)\n\n        port_risk = np.sqrt(weights.T @ cov_matrix @ weights)\n        port_risks.append(port_risk)\n\n        port_sharpe = (port_ret - RISK_FREE_RATE) / port_risk\n        port_sharpes.append(port_sharpe)\n\n    port_rets = np.array(port_rets)\n    port_risks = np.array(port_risks)\n\n    plt.scatter(\n        port_risks * 100.0,\n        port_rets * 100.0,\n        c=port_sharpes,\n        cmap=\"viridis\",\n        alpha=0.75,\n    )\n\n    plt.xlabel(\"Risk (%)\")\n    plt.ylabel(\"Expected Returns (%)\")\n    plt.colorbar(label=\"Sharpe Ratio\")\n    plt.grid()\n\n    return port_risks, port_rets, port_sharpes\n\n\nplt.figure(figsize=(16, 8))\nplt.title(\"Random Portfolios\")\nport_generator(rets, cov_matrix)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:07:42.885458Z","iopub.status.idle":"2023-11-19T19:07:42.885987Z","shell.execute_reply.started":"2023-11-19T19:07:42.885718Z","shell.execute_reply":"2023-11-19T19:07:42.885743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Already we can see a frontier forming. Provide also are Sharpe Ratios to be able to compare portfolios. The ratio tell us if the portfolio is better than the risk free option, usually if it's 1 or above:\n\n$$ Sharpe = \\frac{R_p - R_f}{\\sigma_p} $$\n\nwhere:\n- `Rp` is the portfolio returns.\n- `Rf` is the risk-free rate. As of 11.2023 this is 5%\n- `sigma` is the standard deviation of the portfolio returns.\n\nThe ratio was not the best benchmark here neighter the variance calculations, as most stocks in this market regime had extreme positive variance - in this case we would have done better with the Sortino Ratio and half-variance calculations that measures negative risk (less than the risk free rate).\n\n# Finding an Investable Universe\n\nFor simplicity while building portfolios and frontiers, we will ignore riskless lending and borrowing and assume unlimited short selling is possible - this means you'll see negative weights and weights that are more than 100%. TAll will add up to 100% if you include the negative weights, this means that we will 'leverage' our long positions with income from the short selling, e.g. -20% DIS and 100 % AAPL:\n- We long 100% AAPL, short sell 20% DIS netting us additional funds at the expense of interest and the return of the stock to a counter party (which we are also simplifying out),\n- We use the extra 20% gained to buy another 20% of AAPL stock.\n\nThe following sections are better described with a larger universe of instruments at a larger timeframe for diversification:","metadata":{}},{"cell_type":"code","source":"tickers = [\n    \"AAPL\",\n    \"DIS\",\n    \"MSFT\",\n    \"AMZN\",\n    \"GOOG\",\n]\nSTART_DATE = \"2014-01-01\"\nEND_DATE = \"2022-12-31\"\n\ntickers_orig_df = load_ticker_prices_ts_df(tickers, START_DATE, END_DATE)\ntickers_df = tickers_orig_df.dropna(axis=1).pct_change().dropna()  # first % is NaN\n\nrets = ((1 + tickers_df).prod() ** (TRADING_DAYS_IN_YEAR / len(tickers_df))) - 1\ncov_matrix = tickers_df.cov() * TRADING_DAYS_IN_YEAR\n\nplt.figure(figsize=(16, 8))\nplt.title(\"Random Portfolios\")\nport_risks, port_rets, port_sharpes = port_generator(rets, cov_matrix)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:07:42.889762Z","iopub.status.idle":"2023-11-19T19:07:42.890219Z","shell.execute_reply.started":"2023-11-19T19:07:42.889979Z","shell.execute_reply":"2023-11-19T19:07:42.889997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets build 2 portfolios as benchmarks:\n1. **Minimum Variance Portfolio (MVP)** - The MVP is the tip of the frontier and the least volatile with adequet returns, any portfolio under it delivers lesser utility to the investor for its risk.\n2. **Tangency Portfolio (TAN)** - The Market portfolio on the Capital Market Line (CML), and is the highest point of tageny, maximising the Sharpe Ratio and therefore the risk adjusted returns.\n\nTo get to those portfolios, we approximate the inverse of the covariance (called precision matrix) to get the `min_risk_vect` and `expect_ret_vect`  dot products, that will contribute to the risk adjustment.\nThe MVP solution is straightforwrd, all portfolio attibutes are adjusted by the `min_risk_vect` . The TAN is the same, but adjusted by the `expect_ret_vect` vector.","metadata":{}},{"cell_type":"code","source":"# Equal-weighted portfolio useful for matrix operations\nequal_weights = np.ones(len(rets))\n\nrets = ((1 + tickers_df).prod() ** (TRADING_DAYS_IN_YEAR / len(tickers_df))) - 1\ncov_matrix = tickers_df.cov() * TRADING_DAYS_IN_YEAR\n\n# Min variance weights\ninv_cov_matrix = np.linalg.pinv(cov_matrix)\nmin_risk_vect = equal_weights @ inv_cov_matrix\nexpect_ret_vect = inv_cov_matrix @ rets\n\n# Minimum variance portfolio\n# Weights are normalized to sum to 1, and risk to std deviation.\nmvp_weights = min_risk_vect / np.sum(min_risk_vect)\nmvp_ret = mvp_weights @ rets\nmvp_risk = np.sqrt(mvp_weights.T @ cov_matrix @ mvp_weights)\n\n# Tangency portfolio\ntan_weights = expect_ret_vect / np.sum(expect_ret_vect)\ntan_ret = tan_weights @ rets\ntan_risk = np.sqrt(tan_weights.T @ cov_matrix @ tan_weights)\n\nsummary_data = {\n    \"Asset\": tickers,\n    \"MVP Weights\": mvp_weights,\n    \"TAN Weights\": tan_weights,\n}\n\nprint(f\"mvp_ret: {mvp_ret*100:0.02f}%, mvp_risk {mvp_risk*100:0.02f}%\")\nprint(f\"tan_ret: {tan_ret*100:0.02f}%, tan_risk {tan_risk*100:0.02f}%\")\n\nsummary_df = pd.DataFrame(summary_data)\nsummary_df.T","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:07:42.891648Z","iopub.status.idle":"2023-11-19T19:07:42.892037Z","shell.execute_reply.started":"2023-11-19T19:07:42.891852Z","shell.execute_reply":"2023-11-19T19:07:42.891869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create a risk curve by solving the portfolio Risk for the MVP and the expected returns:\n\n$$ \\sigma_p^2 = w_{\\text{mvp}}^2 \\cdot \\sigma_{\\text{mvp}}^2 + w_{\\text{E(R)}}^2 \\cdot \\sigma_{\\text{E(R)}}^2 + 2 \\cdot w_{\\text{mvp}} \\cdot w_{\\text{E(r)}} \\cdot \\text{Cov}(R_{\\text{mvp}}, E(R)) $$\n\nWhere:\n- `W mvp` is the weights of all assets in the MVP.\n- `E(R)` is the weights associated with the expected returns for all portfolios along the curve.\n- `Sigma^2 MVP` is the variance of the returns of the MVP.\n- `Sigma^2 E(R)` is the variance of the expected returns of all portfolios.\n- `Cov` is the covariance between the returns of the MVP and the expected returns of all portfolios.\n\nThe above is normalized by the utility function and square root.\n\nFinally we will add a Market Capital Line (MCL) to represent the market's risk and returns at the time of this analysis, any portfolio under this line is overpriced and suboptimal, any higher is underpriced. \n\nMCL is calculated on every portofolio as follows:\n\n$$ E(R_p) = R_f + \\frac{\\sigma_i}{\\sigma_M} \\cdot (E(R_M) - R_f) $$\n\n\nWhere:\n- `E(Rp)`: Expected return on portfolio `i`.\n- `Rf`: Risk-free rate, represented by our equal weight portfolio's constant term `c`.\n- `Sigma i` and `Sigma m`: Variance of portfolio `i`. In our case its the reciprocal of the risk adjusted market returns, calculated in the quadratic terms `a`.\n- `E(RM)-Rf`: Is the product of the returns and MVP, calculated in the linear term `b`.\n\nWhen plotted against the expected returns, the CML will intercept the efficient frontier on the TAN portfolio, this being the most optimal market portfolio. ","metadata":{}},{"cell_type":"code","source":"MAX_RETS = 0.51\nTEN_BASIS_POINTS = 0.0001 * 10\n\nc = np.sum(equal_weights * min_risk_vect)  # Constant term\nb = np.sum(rets * min_risk_vect)  # Linear term\na = np.sum(rets * expect_ret_vect)  # Quadratic term\nutility_func = (a * c) + (-(b**2))  # U(X) to penalize risk\n\n# The frontier curve & MCL, scaled by utility function\nexp_rets = np.arange(0, MAX_RETS, TEN_BASIS_POINTS)\nports_risk_frontier = np.sqrt(\n    ((c * (exp_rets**2)) - (2 * b * exp_rets) + a) / utility_func\n)\nmcl_vector = exp_rets * (1 / np.sqrt(a))\n\nplt.figure(figsize=(12, 6))\nplt.plot(\n    ports_risk_frontier,\n    exp_rets,\n    linestyle=\"--\",\n    color=\"blue\",\n    label=\"Efficient Frontier\",\n    linewidth=2,\n    alpha=0.6,\n)\nplt.plot(\n    mcl_vector,\n    exp_rets,\n    label=\"MCL\",\n    linewidth=2,\n    alpha=0.6,\n    color=\"black\",\n)\n\nplt.scatter(mvp_risk, mvp_ret, color=\"green\", label=\"MVP\")\nplt.annotate(\n    f\"MVP\\nRisk: {mvp_risk*100:.2f}%\\nReturn: {mvp_ret*100:.2f}%\",\n    (mvp_risk, mvp_ret),\n    textcoords=\"offset points\",\n    xytext=(-30, 10),\n)\nplt.scatter(tan_risk, tan_ret, color=\"red\", label=\"TAN\")\nplt.annotate(\n    f\"Tangency\\nRisk: {tan_risk*100:.2f}%\\nReturn: {tan_ret*100:.2f}%\",\n    (tan_risk, tan_ret),\n    textcoords=\"offset points\",\n    xytext=(10, 10),\n)\n\nplt.legend(loc=\"upper left\", fontsize=10)\nplt.xlabel(\"Risk %\")\nplt.ylabel(\"Returns %\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:07:42.894277Z","iopub.status.idle":"2023-11-19T19:07:42.894749Z","shell.execute_reply.started":"2023-11-19T19:07:42.894472Z","shell.execute_reply":"2023-11-19T19:07:42.894550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the above formulas, we can solve the optimal portfolio for a target return, by taking the sum of the products of the expected return and the tangent portfolio contributions, and deduct the MVP contributions. We again normalize the weights with the utlity function denominator.\n\nWe assume that the target return is never less than the MVP return:","metadata":{}},{"cell_type":"code","source":"TARGET_RET = 0.3\n\npt_port = None\nopt_risk = None\nopt_ret = None\n\nmvp_weights = (a - (b * TARGET_RET)) / utility_func\ntan_weights = ((c * TARGET_RET) - b) / utility_func\n\nopt_port_weights = (mvp_weights * min_risk_vect) + (tan_weights * expect_ret_vect)\nopt_ret = np.sum(opt_port_weights * rets)\nopt_risk = np.sqrt(((c * (opt_ret**2)) - (2 * b * opt_ret) + a) / utility_func)\n\nplt.figure(figsize=(12, 6))\nplt.plot(\n    ports_risk_frontier,\n    exp_rets,\n    linestyle=\"--\",\n    color=\"blue\",\n    label=\"Frontier\",\n    linewidth=2,\n    alpha=0.6,\n)\n\nplt.scatter(opt_risk, opt_ret, color=\"green\", label=\"Min Variance\")\nplt.annotate(\n    f\"Optimal \\nRisk: {opt_risk*100:.2f}%\\nReturn: {opt_ret*100:.2f}%\",\n    (opt_risk, opt_ret),\n    textcoords=\"offset points\",\n    xytext=(-30, 10),\n)\n\nplt.legend(loc=\"upper left\", fontsize=10)\nplt.xlabel(\"Risk %\")\nplt.ylabel(\"Returns %\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:07:42.896212Z","iopub.status.idle":"2023-11-19T19:07:42.896666Z","shell.execute_reply.started":"2023-11-19T19:07:42.896407Z","shell.execute_reply":"2023-11-19T19:07:42.896425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's add everything together in a graph so we can visualize our optimal and frontier portfolios:","metadata":{}},{"cell_type":"code","source":"# Add portfolios sharpe\nopt_sharpe = (opt_ret - RISK_FREE_RATE) / opt_risk\nmvp_sharpe = (mvp_ret - RISK_FREE_RATE) / mvp_risk\ntan_sharpe = (tan_ret - RISK_FREE_RATE) / tan_risk\n\nplt.figure(figsize=(20, 12))  # Increase figure size\n\nplt.title(\"Investible Universe\")\n\nplt.scatter(\n    port_risks * 100.0,\n    port_rets * 100.0,\n    c=port_sharpes,\n    cmap=\"viridis\",\n    alpha=0.75,\n    s=50,  # Adjust the size of the scatter points\n)\n\nplt.plot(\n    ports_risk_frontier * 100,\n    exp_rets * 100,\n    linestyle=\"--\",\n    color=\"blue\",\n    label=\"Frontier\",\n    linewidth=2,\n    alpha=0.6,\n)\n\n# Adjust the size of the optimal point\nplt.scatter(\n    opt_risk * 100,\n    opt_ret * 100,\n    color=\"green\",\n    marker=\"x\",\n    s=150,\n    label=\"Optimal Expected Returns\",\n)\nplt.annotate(\n    f\"Optimal Expected \\nRisk: {opt_risk*100:.2f}%\\nReturn: {opt_ret*100:.2f}%\\nShapre: {opt_sharpe:.2f}\",\n    (opt_risk * 100, opt_ret * 100),\n    textcoords=\"offset points\",\n    xytext=(-30, 20),  # Adjust the annotation position\n    fontsize=12,  # Adjust the font size\n)\n\nplt.plot(\n    mcl_vector * 100,\n    exp_rets * 100,\n    label=\"MCL\",\n    linewidth=2,\n    alpha=0.6,\n    color=\"black\",\n)\n\n# Adjust the size and position of the MVP point\nplt.scatter(\n    mvp_risk * 100,\n    mvp_ret * 100,\n    color=\"Black\",\n    label=\"MVP\",\n    marker=\"x\",\n    s=150,\n)\nplt.annotate(\n    f\"MVP\\nRisk: {mvp_risk*100:.2f}%\\nReturn: {mvp_ret*100:.2f}%\\nShapre: {mvp_sharpe:.2f}\",\n    (mvp_risk * 100, mvp_ret * 100),\n    textcoords=\"offset points\",\n    xytext=(-30, 20),\n    fontsize=12,\n)\n\n# Adjust the size and position of the Tangency point\nplt.scatter(\n    tan_risk * 100,\n    tan_ret * 100,\n    color=\"red\",\n    label=\"TAN\",\n    marker=\"x\",\n    s=150,\n)\nplt.annotate(\n    f\"Tangency\\nRisk: {tan_risk*100:.2f}%\\nReturn: {tan_ret*100:.2f}%\\nShapre: {tan_sharpe:.2f}\",\n    (tan_risk * 100, tan_ret * 100),\n    textcoords=\"offset points\",\n    xytext=(10, 20),\n    fontsize=12,\n)\n\nplt.xlabel(\"Risk (%)\")\nplt.ylabel(\"Expected Returns (%)\")\nplt.colorbar(label=\"Sharpe Ratio\")\nplt.grid()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T19:07:42.898222Z","iopub.status.idle":"2023-11-19T19:07:42.898787Z","shell.execute_reply.started":"2023-11-19T19:07:42.898503Z","shell.execute_reply":"2023-11-19T19:07:42.898530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\nThis was not an easy article to digest, though it described a fundamental concept in quantitative finance. We constructed optimal portfolios, showcased the Capital Market Line, and solved portfolios for risk and returns expectations. We understood how the Minimum Variance and Tangency Portfolios are efficient portfolios, and learned to build these from our universe of assets.\n\nBe warned, if you run the above code on the current market regime only (post-covide 2020-2023) you'll see unexpected results or extreme MVP or TAN weights, this is because of the high volatility the market experienced in this period.\n\n\n![The MVP built by a quant cowpoke Mind Valley 11.2023](https://raw.githubusercontent.com/adamd1985/quant_research/main/images/mvp_ending.png)\n\n## References\n\n- https://www.investopedia.com/terms/i/indifferencecurve.asp\n- https://www.investopedia.com/ask/answers/041315/how-covariance-used-portfolio-theory.asp \n- https://www.investopedia.com/ask/answers/what-basis-point-bps/\n- https://www.investopedia.com/terms/c/cml.asp\n\n\n## Github\n\nArticle here is also available on [Github](https://github.com/adamd1985/quant_research/blob/main/efficient-frontier-quant.ipynb)\n\nKaggle notebook available [here](https://www.kaggle.com/code/addarm/efficient-frontier-quant)\n\n\n## Media\n\nAll media used (in the form of code or images) are either solely owned by me, acquired through licensing, or part of the Public Domain and granted use through Creative Commons License.\n\n## CC Licensing and Use\n\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>.","metadata":{"papermill":{"duration":0.037345,"end_time":"2023-11-05T18:01:12.947046","exception":false,"start_time":"2023-11-05T18:01:12.909701","status":"completed"},"tags":[]}}]}